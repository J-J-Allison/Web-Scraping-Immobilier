{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7799e125-6cc3-4333-bf8f-889561f8fa4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdfda6c-8141-4861-b5e2-e0af87326fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codes URL des départements français\n",
    "DEPARTEMENTS = {\n",
    "    \"Ain\": \"ld01\", \"Aisne\": \"ld02\", \"Allier\": \"ld03\", \"Alpes-de-Haute-Provence\": \"ld04\",\n",
    "    \"Hautes-Alpes\": \"ld05\", \"Alpes-Maritimes\": \"ld06\", \"Ardèche\": \"ld07\", \"Ardennes\": \"ld08\",\n",
    "    \"Ariège\": \"ld09\", \"Aube\": \"ld10\", \"Aude\": \"ld11\", \"Aveyron\": \"ld12\", \"Bouches-du-Rhône\": \"ld13\",\n",
    "    \"Calvados\": \"ld14\", \"Cantal\": \"ld15\", \"Charente\": \"ld16\", \"Charente-Maritime\": \"ld17\",\n",
    "    \"Cher\": \"ld18\", \"Corrèze\": \"ld19\", \"Corse-du-Sud\": \"ld2A\", \"Haute-Corse\": \"ld2B\",\n",
    "    \"Côte-d'Or\": \"ld21\", \"Côtes-d'Armor\": \"ld22\", \"Creuse\": \"ld23\", \"Dordogne\": \"ld24\",\n",
    "    \"Doubs\": \"ld25\", \"Drôme\": \"ld26\", \"Eure\": \"ld27\", \"Eure-et-Loir\": \"ld28\", \"Finistère\": \"ld29\",\n",
    "    \"Gard\": \"ld30\", \"Haute-Garonne\": \"ld31\", \"Gers\": \"ld32\", \"Gironde\": \"ld33\", \"Hérault\": \"ld34\",\n",
    "    \"Ille-et-Vilaine\": \"ld35\", \"Indre\": \"ld36\", \"Indre-et-Loire\": \"ld37\", \"Isère\": \"ld38\",\n",
    "    \"Jura\": \"ld39\", \"Landes\": \"ld40\", \"Loir-et-Cher\": \"ld41\", \"Loire\": \"ld42\",\n",
    "    \"Haute-Loire\": \"ld43\", \"Loire-Atlantique\": \"ld44\", \"Loiret\": \"ld45\", \"Lot\": \"ld46\",\n",
    "    \"Lot-et-Garonne\": \"ld47\", \"Lozère\": \"ld48\", \"Maine-et-Loire\": \"ld49\", \"Manche\": \"ld50\",\n",
    "    \"Marne\": \"ld51\", \"Haute-Marne\": \"ld52\", \"Mayenne\": \"ld53\", \"Meurthe-et-Moselle\": \"ld54\",\n",
    "    \"Meuse\": \"ld55\", \"Morbihan\": \"ld56\", \"Moselle\": \"ld57\", \"Nièvre\": \"ld58\", \"Nord\": \"ld59\",\n",
    "    \"Oise\": \"ld60\", \"Orne\": \"ld61\", \"Pas-de-Calais\": \"ld62\", \"Puy-de-Dôme\": \"ld63\",\n",
    "    \"Pyrénées-Atlantiques\": \"ld64\", \"Hautes-Pyrénées\": \"ld65\", \"Pyrénées-Orientales\": \"ld66\",\n",
    "    \"Bas-Rhin\": \"ld67\", \"Haut-Rhin\": \"ld68\", \"Rhône\": \"ld69\", \"Haute-Saône\": \"ld70\",\n",
    "    \"Saône-et-Loire\": \"ld71\", \"Sarthe\": \"ld72\", \"Savoie\": \"ld73\", \"Haute-Savoie\": \"ld74\",\n",
    "    \"Paris\": \"ld75\", \"Seine-Maritime\": \"ld76\", \"Seine-et-Marne\": \"ld77\", \"Yvelines\": \"ld78\",\n",
    "    \"Deux-Sèvres\": \"ld79\", \"Somme\": \"ld80\", \"Tarn\": \"ld81\", \"Tarn-et-Garonne\": \"ld82\",\n",
    "    \"Var\": \"ld83\", \"Vaucluse\": \"ld84\", \"Vendée\": \"ld85\", \"Vienne\": \"ld86\", \"Haute-Vienne\": \"ld87\",\n",
    "    \"Vosges\": \"ld88\", \"Yonne\": \"ld89\", \"Territoire de Belfort\": \"ld90\", \"Essonne\": \"ld91\",\n",
    "    \"Hauts-de-Seine\": \"ld92\", \"Seine-Saint-Denis\": \"ld93\", \"Val-de-Marne\": \"ld94\",\n",
    "    \"Val-d'Oise\": \"ld95\", \"Guadeloupe\": \"ld971\", \"Martinique\": \"ld972\", \"Guyane\": \"ld973\",\n",
    "    \"La Réunion\": \"ld974\", \"Mayotte\": \"ld976\"\n",
    "}\n",
    "\n",
    "# Définition des filtres de biens (type d'annonce)\n",
    "FILTRES_BIENS = {\n",
    "    \"Maison\": \"th\",\n",
    "    \"Appartement\": \"tf\"\n",
    "}\n",
    "\n",
    "# Nombre maximum de pages à extraire par département (limite du site)\n",
    "NB_PAGES_MAX = 30\n",
    "\n",
    "# Définition des filtres de superficie (code url, nom pour l'affichage)\n",
    "# Nous utilisons les bornes données pour créer des intervalles consécutifs.\n",
    "FILTRES_SUPERFICIE = {\n",
    "    \"s-20\": \"0m² à 20m²\",     # Superficie Max 20\n",
    "    \"s20-25\": \"20m² à 25m²\",  # Min 20, Max 25\n",
    "    \"s25-30\": \"25m² à 30m²\",\n",
    "    \"s30-35\": \"30m² à 35m²\",\n",
    "    \"s35-40\": \"35m² à 40m²\",\n",
    "    \"s40-50\": \"40m² à 50m²\",\n",
    "    \"s50-60\": \"50m² à 60m²\",\n",
    "    \"s60-70\": \"60m² à 70m²\",\n",
    "    \"s70-80\": \"70m² à 80m²\",\n",
    "    \"s80-90\": \"80m² à 90m²\",\n",
    "    \"s90-100\": \"90m² à 100m²\",\n",
    "    \"s100-120\": \"100m² à 120m²\",\n",
    "    \"s120-140\": \"120m² à 140m²\",\n",
    "    \"s140-160\": \"140m² à 160m²\",\n",
    "    \"s160-180\": \"160m² à 180m²\",\n",
    "    \"s180-200\": \"180m² à 200m²\",\n",
    "    \"s200-250\": \"200m² à 250m²\",\n",
    "    \"s250\": \"Plus de 250m²\" # Superficie Min 250 (sans max)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7e4557-488a-4ff3-923c-ae7863c18900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération d'une page\n",
    "\n",
    "def get_annonces_page(code_filtre, code_departement, code_superficie, page_num):\n",
    "    \"\"\"\n",
    "    Retourne les liens trouvés sur une page filtrée par type de bien, département et superficie.\n",
    "    Exemple d'URL : https://www.etreproprio.com/annonces/th.ld75.s20-25.odd.g2#list\n",
    "    \"\"\"\n",
    "    # Construction du préfixe qui inclut tous les filtres (ex: th.ld75.s20-25)\n",
    "    prefixe = f\"{code_filtre}.{code_departement}.{code_superficie}\"\n",
    "    \n",
    "    if page_num == 1:\n",
    "        # URL pour la première page (ex: th.ld75.s20-25#list)\n",
    "        url = f\"https://www.etreproprio.com/annonces/{prefixe}#list\"\n",
    "    else:\n",
    "        # URL pour la page N > 1 (ex: th.ld75.s20-25.odd.g2#list)\n",
    "        url = f\"https://www.etreproprio.com/annonces/{prefixe}.odd.g{page_num}#list\"\n",
    "\n",
    "    print(f\"\\n Chargement URL : {url}\")\n",
    "\n",
    "    try:\n",
    "        r = requests.get(url)\n",
    "        r.raise_for_status() # Lève une erreur pour les mauvaises réponses (4xx ou 5xx)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Erreur de requête pour l'URL {url}: {e}\")\n",
    "        return []\n",
    "\n",
    "    soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "\n",
    "    zone = soup.find(\"div\", class_=\"ep-search-list-wrapper\")\n",
    "    if not zone:\n",
    "        # Ce message est normal si le filtre ne retourne aucune annonce\n",
    "        return []\n",
    "\n",
    "    links = []\n",
    "    for a in zone.find_all(\"a\", href=True):\n",
    "        href = a[\"href\"]\n",
    "        if \"https://www.etreproprio.com/immobilier-\" in href:\n",
    "            links.append(href)\n",
    "\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049da8a7-b950-43f1-9f85-32065c60a6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction des infos de l'annonce\n",
    "\n",
    "def extract_info(url):\n",
    "    \"\"\"Extrait prix, surfaces (int/terrain), nb pièces, ville et code postal d’une annonce.\"\"\"\n",
    "    \n",
    "    # Valeurs par défaut en cas d'erreur ou d'absence\n",
    "    prix = \"N/A\"\n",
    "    surface_interieure = \"N/A\"\n",
    "    surface_terrain = \"N/A\"\n",
    "    nb_pieces = \"N/A\"\n",
    "    ville = \"N/A\"\n",
    "    code_postal = \"N/A\"\n",
    "\n",
    "    try:\n",
    "        r = requests.get(url, timeout=15)\n",
    "        r.raise_for_status()\n",
    "        soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Erreur lors de la récupération de l'annonce {url}: {e}\")\n",
    "        return prix, surface_interieure, surface_terrain, nb_pieces, ville, code_postal\n",
    "\n",
    "    # 1. Prix\n",
    "    try:\n",
    "        prix = soup.find(\"div\", class_=\"ep-price\").text.strip().replace(\" \", \"\").replace(\"\\xa0\", \"\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # 2. Surface Intérieure (ep-area)\n",
    "    # Correction : Conserver seulement la première valeur (avant le '/')\n",
    "    try:\n",
    "        text = soup.find(\"div\", class_=\"ep-area\").text.strip().replace(\" \", \"\").replace(\"\\xa0\", \"\")\n",
    "        surface_interieure = text.split('/')[0]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # 3. Surface Terrain (dtl-main-surface-terrain)\n",
    "    # Correction : Nettoyage du préfixe '/' s'il existe.\n",
    "    try:\n",
    "        surface_terrain_raw = soup.find(\"span\", class_=\"dtl-main-surface-terrain\").text.strip().replace(\" \", \"\").replace(\"\\xa0\", \"\")\n",
    "        if surface_terrain_raw.startswith('/'):\n",
    "            surface_terrain = surface_terrain_raw[1:].strip()\n",
    "        else:\n",
    "            surface_terrain = surface_terrain_raw\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # 4. Nombre de pièces (ep-room)\n",
    "    try:\n",
    "        nb_pieces = soup.find(\"div\", class_=\"ep-room\").text.strip().replace(\"pièces\", \"\").replace(\"pièce\", \"\").strip()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # 5 & 6. Ville et Code Postal (ep-loc)\n",
    "    try:\n",
    "        loc_text = soup.find(\"div\", class_=\"ep-loc\").text.strip()\n",
    "        loc_text = loc_text.replace(\"—\", \"\").replace(\"\\xa0\", \" \").strip()\n",
    "        \n",
    "        parts = loc_text.split()\n",
    "        \n",
    "        if parts and parts[-1].isdigit():\n",
    "            code_postal_raw = parts[-1]\n",
    "            \n",
    "            # CORRECTION : zfill(5) garantit 5 chiffres, ajoutant des zéros si nécessaire (ex: \"1800\" devient \"01800\")\n",
    "            code_postal = code_postal_raw.zfill(5) \n",
    "            \n",
    "            # Ville : tout ce qui précède le code postal\n",
    "            ville = \" \".join(parts[:-1]).strip()\n",
    "        else:\n",
    "            ville = loc_text\n",
    "            code_postal = \"N/A\"\n",
    "            \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return prix, surface_interieure, surface_terrain, nb_pieces, ville, code_postal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e1fd05-59b4-4fe5-b4a2-e9fde0584835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction simplifiée pour vérifier l'existence des pages\n",
    "\n",
    "def get_annonces_page_count(code_filtre, code_departement, code_superficie, page_num):\n",
    "    \"\"\"\n",
    "    Vérifie si une page spécifique contient des annonces.\n",
    "    Retourne le nombre d'annonces trouvées (0 si vide ou erreur).\n",
    "    \"\"\"\n",
    "    # Construction de l'URL comme dans get_annonces_page\n",
    "    prefixe = f\"{code_filtre}.{code_departement}.{code_superficie}\"\n",
    "    \n",
    "    if page_num == 1:\n",
    "        url = f\"https://www.etreproprio.com/annonces/{prefixe}#list\"\n",
    "    else:\n",
    "        url = f\"https://www.etreproprio.com/annonces/{prefixe}.odd.g{page_num}#list\"\n",
    "\n",
    "    try:\n",
    "        r = requests.get(url, timeout=10) # Ajout d'un timeout pour les requêtes de vérification\n",
    "        r.raise_for_status()\n",
    "    except requests.exceptions.RequestException:\n",
    "        return 0 # Retourne 0 si la requête échoue (page non trouvée, erreur 404/500, etc.)\n",
    "\n",
    "    soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "\n",
    "    # Cherche la zone contenant les annonces\n",
    "    zone = soup.find(\"div\", class_=\"ep-search-list-wrapper\")\n",
    "    if not zone:\n",
    "        return 0\n",
    "\n",
    "    # Compte le nombre de liens d'annonces trouvés\n",
    "    links_count = 0\n",
    "    for a in zone.find_all(\"a\", href=True):\n",
    "        href = a[\"href\"]\n",
    "        if \"https://www.etreproprio.com/immobilier-\" in href:\n",
    "            links_count += 1\n",
    "\n",
    "    return links_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d1c3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================\n",
    "# TRAITEMENT AVEC EXÉCUTION PARALLÈLE\n",
    "# =================================================================\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "MAX_WORKERS = 8 # Nombre de requêtes d'extraction de détails lancées simultanément\n",
    "\n",
    "total_annonces_global = 0  # Compteur des annonces uniques extraites\n",
    "ALL_ANNONCES = []          # Liste des annonces uniques\n",
    "PROCESSED_LINKS = set()    # Set pour stocker et vérifier les liens uniques\n",
    "\n",
    "# Boucle 0 : Type de bien\n",
    "for nom_bien, code_bien in FILTRES_BIENS.items():\n",
    "    \n",
    "    print(\"\\n\" + \"#\"*100)\n",
    "    print(f\"COMMENCEMENT DE L'EXTRACTION POUR LE TYPE DE BIEN : {nom_bien}\")\n",
    "    print(\"#\"*100)\n",
    "\n",
    "    # Boucle 1 : Départements\n",
    "    for nom_departement, code_departement in DEPARTEMENTS.items():\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"      DÉPARTEMENT EN COURS : {nom_departement} ({code_departement})\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "        # Boucle 2 : Superficies\n",
    "        for code_superficie, nom_superficie in FILTRES_SUPERFICIE.items():\n",
    "            \n",
    "            print(\"\\n\" + \"-\"*50)\n",
    "            print(f\"   FILTRE SUPERFICIE : {nom_superficie} ({code_superficie})\")\n",
    "            print(\"-\"*50)\n",
    "\n",
    "            # 1. PHASE DE COLLECTE DES LIENS (SÉQUENTIELLE)\n",
    "            links_to_extract_details = []\n",
    "            \n",
    "            for page_num in range(1, NB_PAGES_MAX + 1):\n",
    "\n",
    "                liens_page = get_annonces_page(code_bien, code_departement, code_superficie, page_num)\n",
    "\n",
    "                if not liens_page:\n",
    "                    print(f\"\\n[INFO] Arrêt : Aucune annonce trouvée sur la Page {page_num}. Fin de la pagination.\")\n",
    "                    break\n",
    "                \n",
    "                print(f\"Page {page_num} ({len(liens_page)} liens trouvés)\")\n",
    "\n",
    "                # Dédoublonnage et ajout des liens uniques à la liste de traitement parallèle\n",
    "                for lien in liens_page:\n",
    "                    if lien not in PROCESSED_LINKS:\n",
    "                        PROCESSED_LINKS.add(lien)\n",
    "                        links_to_extract_details.append(lien)\n",
    "            \n",
    "            # 2. PHASE D'EXTRACTION DES DÉTAILS (PARALLÈLE)\n",
    "            \n",
    "            nb_liens_uniques = len(links_to_extract_details)\n",
    "            if nb_liens_uniques > 0:\n",
    "                print(f\"   [INFO] Lancement de l'extraction parallèle ({MAX_WORKERS} workers) pour {nb_liens_uniques} annonces uniques...\")\n",
    "                \n",
    "                with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "                    \n",
    "                    # Soumettre la tâche extract_info pour chaque lien\n",
    "                    future_to_url = {executor.submit(extract_info, link): link for link in links_to_extract_details}\n",
    "                    \n",
    "                    for future in as_completed(future_to_url):\n",
    "                        lien = future_to_url[future]\n",
    "                        try:\n",
    "                            # Récupérer les résultats du thread\n",
    "                            prix, surface_interieure, surface_terrain, nb_pieces, ville, code_postal = future.result()\n",
    "                            \n",
    "                            annonce_data = {\n",
    "                                \"Type de Bien\": nom_bien,\n",
    "                                \"Departement\": nom_departement,\n",
    "                                \"Ville\": ville,\n",
    "                                \"Code_Postal\": code_postal,\n",
    "                                \"Nb_Pieces\": nb_pieces,\n",
    "                                \"Surface_Interieure\": surface_interieure,\n",
    "                                \"Surface_Terrain\": surface_terrain,\n",
    "                                \"Prix\": prix,\n",
    "                                \"Lien\": lien\n",
    "                            }\n",
    "                            \n",
    "                            ALL_ANNONCES.append(annonce_data)\n",
    "                            \n",
    "                        except Exception as exc:\n",
    "                            # Gérer les erreurs de connexion/timeout dans les threads\n",
    "                            print(f'   [ERREUR PARALLÈLE] Le lien {lien} a généré une exception: {exc}')\n",
    "\n",
    "            print(f\"\\n--- {nb_liens_uniques} ANNONCES UNIQUES TRAITÉES POUR LE FILTRE {nom_superficie} ---\")\n",
    "            \n",
    "# Mettre à jour le compteur global\n",
    "total_annonces_global = len(ALL_ANNONCES)\n",
    "\n",
    "\n",
    "# Bloc de Sauvegarde CSV (Inchangé dans sa logique)\n",
    "\n",
    "print(\"\\n\\n\" + \"#\"*80)\n",
    "print(f\"### FIN DE L'EXTRACTION - SAUVEGARDE DES DONNÉES UNIQUES ###\")\n",
    "print(\"#\"*80)\n",
    "\n",
    "if ALL_ANNONCES:\n",
    "    \n",
    "    fieldnames = list(ALL_ANNONCES[0].keys())\n",
    "    output_filename = \"annonces_etreproprio_maisons_appartements.csv\"\n",
    "    \n",
    "    try:\n",
    "        with open(output_filename, 'w', newline='', encoding='utf-8-sig') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames, delimiter=';')\n",
    "\n",
    "            writer.writeheader()\n",
    "            writer.writerows(ALL_ANNONCES)\n",
    "\n",
    "        print(f\"\\n[SUCCÈS] Toutes les données ont été sauvegardées dans le fichier : {output_filename}\")\n",
    "        print(f\"Nombre total d'annonces uniques extraites : {total_annonces_global}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n[ERREUR] Impossible de sauvegarder le fichier CSV : {e}\")\n",
    "else:\n",
    "    print(\"\\n[INFO] Aucune donnée à sauvegarder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956e1a0d-b5c2-4651-96df-bb49ca73c67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traitement\n",
    "\n",
    "total_annonces_global = 0 # Nombre total de liens trouvés (y compris doublons)\n",
    "ALL_ANNONCES = [] # Liste des annonces uniques\n",
    "PROCESSED_LINKS = set() # Set pour stocker et vérifier les liens uniques\n",
    "\n",
    "# Boucle 0 : Type de bien\n",
    "for nom_bien, code_bien in FILTRES_BIENS.items():\n",
    "    \n",
    "    print(\"\\n\" + \"#\"*100)\n",
    "    print(f\"COMMENCEMENT DE L'EXTRACTION POUR LE TYPE DE BIEN : {nom_bien}\")\n",
    "    print(\"#\"*100)\n",
    "\n",
    "    # Boucle 1 : Départements\n",
    "    for nom_departement, code_departement in DEPARTEMENTS.items():\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"      DÉPARTEMENT EN COURS : {nom_departement} ({code_departement})\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "        # Boucle 2 : Superficies\n",
    "        for code_superficie, nom_superficie in FILTRES_SUPERFICIE.items():\n",
    "            \n",
    "            print(\"\\n\" + \"-\"*50)\n",
    "            print(f\"   FILTRE SUPERFICIE : {nom_superficie} ({code_superficie})\")\n",
    "            print(\"-\"*50)\n",
    "\n",
    "            total_annonces_filtre = 0\n",
    "            \n",
    "            # Boucle 3 : Pages (1 à 30)\n",
    "            for page_num in range(1, NB_PAGES_MAX + 1):\n",
    "\n",
    "                liens = get_annonces_page(code_bien, code_departement, code_superficie, page_num)\n",
    "\n",
    "                if not liens:\n",
    "                    print(f\"\\n[INFO] Arrêt : Aucune annonce trouvée sur la Page {page_num}. Fin de la pagination pour ce filtre.\")\n",
    "                    break\n",
    "                \n",
    "                print(f\"Page {page_num} ({len(liens)} annonces trouvées)\")\n",
    "                total_annonces_filtre += len(liens)\n",
    "                total_annonces_global += len(liens) # Compte le nombre de liens trouvés (brut)\n",
    "\n",
    "                # Dédoublonnage\n",
    "                for lien in liens:\n",
    "                    \n",
    "                    if lien in PROCESSED_LINKS:\n",
    "                        # Si le lien est déjà dans l'ensemble, on l'ignore (doublon)\n",
    "                        print(f\"   [SKIP] Doublon détecté, lien ignoré: {lien}\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Le lien est unique, on l'ajoute à l'ensemble pour le marquer comme traité\n",
    "                    PROCESSED_LINKS.add(lien)\n",
    "                    \n",
    "                    # Récupération de toutes les infos\n",
    "                    prix, surface_interieure, surface_terrain, nb_pieces, ville, code_postal = extract_info(lien)\n",
    "                    \n",
    "                    # 1. Création d'un dictionnaire pour cette annonce\n",
    "                    annonce_data = {\n",
    "                        \"Type de Bien\": nom_bien,\n",
    "                        \"Departement\": nom_departement,\n",
    "                        \"Ville\": ville,\n",
    "                        \"Code_Postal\": code_postal,\n",
    "                        \"Nb_Pieces\": nb_pieces,\n",
    "                        \"Surface_Interieure\": surface_interieure,\n",
    "                        \"Surface_Terrain\": surface_terrain,\n",
    "                        \"Prix\": prix,\n",
    "                        \"Lien\": lien\n",
    "                    }\n",
    "                    \n",
    "                    # 2. Ajout à la liste globale\n",
    "                    ALL_ANNONCES.append(annonce_data)\n",
    "                    \n",
    "                    print(f\"   > [{nom_bien} - {ville}] Prix: {prix}\")\n",
    "\n",
    "            print(f\"\\n--- TOTAL ANNONCES {nom_bien} / {nom_departement} ({nom_superficie}): {total_annonces_filtre} ---\")\n",
    "\n",
    "\n",
    "# Bloc de Sauvegarde CSV\n",
    "# Ce bloc utilise la liste ALL_ANNONCES qui ne contient maintenant que les liens uniques\n",
    "\n",
    "print(\"\\n\\n\" + \"#\"*80)\n",
    "print(f\"### FIN DE L'EXTRACTION - SAUVEGARDE DES DONNÉES UNIQUES ###\")\n",
    "print(\"#\"*80)\n",
    "\n",
    "if ALL_ANNONCES:\n",
    "    \n",
    "    fieldnames = list(ALL_ANNONCES[0].keys())\n",
    "    output_filename = \"annonces_etreproprio_maisons_appartements.csv\"\n",
    "    \n",
    "    try:\n",
    "        with open(output_filename, 'w', newline='', encoding='utf-8-sig') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames, delimiter=';')\n",
    "\n",
    "            writer.writeheader()\n",
    "            writer.writerows(ALL_ANNONCES)\n",
    "\n",
    "        print(f\"\\n[SUCCÈS] Toutes les données ont été sauvegardées dans le fichier : {output_filename}\")\n",
    "        print(f\"Nombre total d'annonces uniques extraites : {len(ALL_ANNONCES)}\")\n",
    "        print(f\"Nombre de liens trouvés (brut, avant dédoublonnage) : {total_annonces_global}\") # Pour comparaison\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n[ERREUR] Impossible de sauvegarder le fichier CSV : {e}\")\n",
    "else:\n",
    "    print(\"\\n[INFO] Aucune donnée à sauvegarder.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
